{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "\u001B[34m\u001B[1myolo\\engine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=mydata.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train48\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\train.cache... 209 images, 0 backgrounds, 0 corrupt: 100%|██████████| 209/209 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\val.cache... 26 images, 0 backgrounds, 0 corrupt: 100%|██████████| 26/26 [00:00<?, ?it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\train48\u001B[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G      1.481      3.049      1.374         51        640: 100%|██████████| 14/14 [03:32<00:00, 15.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO()\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmydata.yaml\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\model.py:283\u001B[0m, in \u001B[0;36mYOLO.train\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mget_model(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, cfg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39myaml)\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel\n\u001B[1;32m--> 283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;66;03m# update model and cfg after training\u001B[39;00m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m}:\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\trainer.py:189\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    187\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, file)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 189\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRANK\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mworld_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\trainer.py:348\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[1;34m(self, rank, world_size)\u001B[0m\n\u001B[0;32m    345\u001B[0m final_epoch \u001B[38;5;241m=\u001B[39m (epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstopper\u001B[38;5;241m.\u001B[39mpossible_stop\n\u001B[0;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mval \u001B[38;5;129;01mor\u001B[39;00m final_epoch:\n\u001B[1;32m--> 348\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetrics, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfitness \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_metrics(metrics\u001B[38;5;241m=\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_loss_items(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetrics, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr})\n\u001B[0;32m    350\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstopper(epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfitness)\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\trainer.py:445\u001B[0m, in \u001B[0;36mBaseTrainer.validate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    442\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;124;03m    Runs validation on test set using self.validator. The returned dict is expected to contain \"fitness\" key.\u001B[39;00m\n\u001B[0;32m    444\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 445\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    446\u001B[0m     fitness \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfitness\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy())  \u001B[38;5;66;03m# use loss as fitness measure if not found\u001B[39;00m\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_fitness \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_fitness \u001B[38;5;241m<\u001B[39m fitness:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\validator.py:167\u001B[0m, in \u001B[0;36mBaseValidator.__call__\u001B[1;34m(self, trainer, model)\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dt[\u001B[38;5;241m2\u001B[39m]:\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining:\n\u001B[1;32m--> 167\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    169\u001B[0m \u001B[38;5;66;03m# postprocess\u001B[39;00m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dt[\u001B[38;5;241m3\u001B[39m]:\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\detect\\train.py:76\u001B[0m, in \u001B[0;36mDetectionTrainer.criterion\u001B[1;34m(self, preds, batch)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcompute_loss\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss \u001B[38;5;241m=\u001B[39m Loss(de_parallel(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel))\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\detect\\train.py:180\u001B[0m, in \u001B[0;36mLoss.__call__\u001B[1;34m(self, preds, batch)\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;66;03m# pboxes\u001B[39;00m\n\u001B[0;32m    178\u001B[0m pred_bboxes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbbox_decode(anchor_points, pred_distri)  \u001B[38;5;66;03m# xyxy, (b, h*w, 4)\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m _, target_bboxes, target_scores, fg_mask, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massigner\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpred_scores\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmoid\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred_bboxes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstride_tensor\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgt_bboxes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43manchor_points\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mstride_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_bboxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_gt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m target_bboxes \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m stride_tensor\n\u001B[0;32m    185\u001B[0m target_scores_sum \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(target_scores\u001B[38;5;241m.\u001B[39msum(), \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\tal.py:104\u001B[0m, in \u001B[0;36mTaskAlignedAssigner.forward\u001B[1;34m(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt)\u001B[0m\n\u001B[0;32m     99\u001B[0m     device \u001B[38;5;241m=\u001B[39m gt_bboxes\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39mfull_like(pd_scores[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbg_idx)\u001B[38;5;241m.\u001B[39mto(device), torch\u001B[38;5;241m.\u001B[39mzeros_like(pd_bboxes)\u001B[38;5;241m.\u001B[39mto(device),\n\u001B[0;32m    101\u001B[0m             torch\u001B[38;5;241m.\u001B[39mzeros_like(pd_scores)\u001B[38;5;241m.\u001B[39mto(device), torch\u001B[38;5;241m.\u001B[39mzeros_like(pd_scores[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39mto(device),\n\u001B[0;32m    102\u001B[0m             torch\u001B[38;5;241m.\u001B[39mzeros_like(pd_scores[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[1;32m--> 104\u001B[0m mask_pos, align_metric, overlaps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_pos_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd_scores\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpd_bboxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_bboxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43manc_points\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mmask_gt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m target_gt_idx, fg_mask, mask_pos \u001B[38;5;241m=\u001B[39m select_highest_overlaps(mask_pos, overlaps, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_max_boxes)\n\u001B[0;32m    109\u001B[0m \u001B[38;5;66;03m# assigned target\u001B[39;00m\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\tal.py:123\u001B[0m, in \u001B[0;36mTaskAlignedAssigner.get_pos_mask\u001B[1;34m(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_pos_mask\u001B[39m(\u001B[38;5;28mself\u001B[39m, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt):\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;66;03m# get anchor_align metric, (b, max_num_obj, h*w)\u001B[39;00m\n\u001B[1;32m--> 123\u001B[0m     align_metric, overlaps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_box_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd_scores\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpd_bboxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgt_bboxes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;66;03m# get in_gts mask, (b, max_num_obj, h*w)\u001B[39;00m\n\u001B[0;32m    125\u001B[0m     mask_in_gts \u001B[38;5;241m=\u001B[39m select_candidates_in_gts(anc_points, gt_bboxes, roll_out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroll_out)\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\tal.py:151\u001B[0m, in \u001B[0;36mTaskAlignedAssigner.get_box_metrics\u001B[1;34m(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes)\u001B[0m\n\u001B[0;32m    149\u001B[0m ind[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m gt_labels\u001B[38;5;241m.\u001B[39mlong()\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# b, max_num_obj\u001B[39;00m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;66;03m# get the scores of each grid for each gt cls\u001B[39;00m\n\u001B[1;32m--> 151\u001B[0m bbox_scores \u001B[38;5;241m=\u001B[39m \u001B[43mpd_scores\u001B[49m\u001B[43m[\u001B[49m\u001B[43mind\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mind\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# b, max_num_obj, h*w\u001B[39;00m\n\u001B[0;32m    153\u001B[0m overlaps \u001B[38;5;241m=\u001B[39m bbox_iou(gt_bboxes\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m2\u001B[39m), pd_bboxes\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m), xywh\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    154\u001B[0m                     CIoU\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m3\u001B[39m)\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    155\u001B[0m align_metric \u001B[38;5;241m=\u001B[39m bbox_scores\u001B[38;5;241m.\u001B[39mpow(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha) \u001B[38;5;241m*\u001B[39m overlaps\u001B[38;5;241m.\u001B[39mpow(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "model = YOLO()\n",
    "model = model.train(data=\"mydata.yaml\", epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "model =YOLO('runs/detect/train46/weights/best.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\val.cache... 26 images, 0 backgrounds, 0 corrupt: 100%|██████████| 26/26 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.24s/it]\n",
      "                   all         26        490     0.0418      0.588      0.365      0.238\n",
      "                  rect         26        490     0.0418      0.588      0.365      0.238\n",
      "Speed: 4.5ms preprocess, 196.2ms inference, 0.0ms loss, 22.8ms postprocess per image\n"
     ]
    }
   ],
   "source": [
    "res = model.val(save=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "\n",
      "image 1/1 C:\\Users\\Nain0414\\DataspellProjects\\YOLOv8-Object-Detection-Transfer-Learning\\144.jpg: 640x640 501.6ms\n",
      "Speed: 4.0ms preprocess, 501.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001B[1mruns\\detect\\predict4\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res=model(\n",
    "    source='144.jpg',\n",
    "    conf=0.15,\n",
    "    save=True,\n",
    "    augment=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([0, 6])\n",
      "dtype: torch.float32\n",
      " + tensor([], size=(0, 6))]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from cv2 import imshow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import cv2\n",
    "#res = model(img)\n",
    "res_plotted = res[0].plot()\n",
    "cv2.imshow(\"result\", res_plotted)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 581, in _build_master\n",
      "    ws.require(__requires__)\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 909, in require\n",
      "    needed = self.resolve(parse_requirements(requirements))\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 800, in resolve\n",
      "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
      "pkg_resources.ContextualVersionConflict: (numpy 1.24.2 (c:\\users\\nain0414\\appdata\\local\\programs\\python\\python310\\lib\\site-packages), Requirement.parse('numpy<1.23.0,>=1.16.5'), {'scipy'})\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\yolo-script.py\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('ultralytics', 'console_scripts', 'yolo')())\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\yolo-script.py\", line 25, in importlib_load_entry_point\n",
      "    return next(matches).load()\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py\", line 171, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.yolo.engine.model import YOLO\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\__init__.py\", line 3, in <module>\n",
      "    from . import v8\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\__init__.py\", line 3, in <module>\n",
      "    from ultralytics.yolo.v8 import classify, detect, segment\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\classify\\__init__.py\", line 3, in <module>\n",
      "    from ultralytics.yolo.v8.classify.predict import ClassificationPredictor, predict\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\classify\\predict.py\", line 5, in <module>\n",
      "    from ultralytics.yolo.engine.predictor import BasePredictor\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\predictor.py\", line 37, in <module>\n",
      "    from ultralytics.nn.autobackend import AutoBackend\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\nn\\autobackend.py\", line 17, in <module>\n",
      "    from ultralytics.yolo.utils import LOGGER, ROOT, yaml_load\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\__init__.py\", line 622, in <module>\n",
      "    SETTINGS = get_settings()\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\__init__.py\", line 568, in get_settings\n",
      "    from ultralytics.yolo.utils.checks import check_version\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\checks.py\", line 17, in <module>\n",
      "    import pkg_resources as pkg\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 3260, in <module>\n",
      "    def _initialize_master_working_set():\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 3234, in _call_aside\n",
      "    f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 3272, in _initialize_master_working_set\n",
      "    working_set = WorkingSet._build_master()\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 583, in _build_master\n",
      "    return cls._build_from_requirements(__requires__)\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 596, in _build_from_requirements\n",
      "    dists = ws.resolve(reqs, Environment())\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 800, in resolve\n",
      "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
      "pkg_resources.ContextualVersionConflict: (numpy 1.24.2 (c:\\users\\nain0414\\appdata\\local\\programs\\python\\python310\\lib\\site-packages), Requirement.parse('numpy<1.23.0,>=1.16.5'), {'scipy'})\n"
     ]
    }
   ],
   "source": [
    "!yolo predict model=yolov8n.pt source='144.jpg' save=True augment=True\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
