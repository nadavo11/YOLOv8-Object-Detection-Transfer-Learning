{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer Learning - training a YOLO v8 Model on our dataset\n",
    "the ultralytics library provides a training environment that we can use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initiate a YOLO Model\n",
    "as a default, we get the YOLO v8 'nano' detector - which is the lightest and fastest one out of the object detection models, pre-trained on an object detection dataset, but it can be changed by passing different arguments for ```model = ```."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = YOLO()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data:\n",
    "yolo object detection dataset has a different format: it needs txt for labels, and images at different folder. we point to it by choosing the ``.yaml`` file configuring the dataset. its a bit of a headache to deal with, so just make sure that the files follow the same structure:\n",
    "\n",
    "üìÅ ultralitics\n",
    "|   üìÅ datasets\n",
    "|   |   üìÅ my_cool_dataset\n",
    "|   |   |   üìÅ images\n",
    "|   |   |   üìÅ labels\n",
    "|   |   üìú my_cool_dataset.yaml\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "\u001B[34m\u001B[1myolo\\engine\\trainer: \u001B[0mtask=detect, mode=train, model=runs/detect/train54/weights/best.pt, data=mydata.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train55\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.autotrackable has been moved to tensorflow.python.trackable.autotrackable. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\train... 489 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 489/489 [00:00<00:00, 1193.35it/s]\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\train.cache\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\val.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<?, ?it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\train55\u001B[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G     0.4064     0.4418     0.8612        128        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [05:33<00:00, 10.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.61s/it]\n",
      "                   all         20        367      0.957      0.649      0.699      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3         0G     0.4721     0.4648     0.8685        147        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [05:01<00:00,  9.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.70s/it]\n",
      "                   all         20        367      0.963      0.651      0.696      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3         0G     0.4453     0.4532      0.868        115        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [05:01<00:00,  9.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.60s/it]\n",
      "                   all         20        367      0.956      0.657      0.706      0.639\n",
      "\n",
      "3 epochs completed in 0.266 hours.\n",
      "Optimizer stripped from runs\\detect\\train55\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train55\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train55\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.07s/it]\n",
      "                   all         20        367      0.957      0.649      0.699      0.641\n",
      "Speed: 3.1ms preprocess, 172.5ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001B[1mruns\\detect\\train55\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train(data=\"mydata.yaml\", epochs=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "\u001B[34m\u001B[1myolo\\engine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=mydata.yaml, epochs=61, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train54\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.Detect                [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.autotrackable has been moved to tensorflow.python.trackable.autotrackable. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\train.cache... 209 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 209/209 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\val.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<?, ?it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\train54\u001B[0m\n",
      "Starting training for 61 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/61         0G      1.481      3.049      1.374         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:57<00:00, 12.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 1.500s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.33s/it]\n",
      "                   all         20        367      0.034      0.444       0.17      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/61         0G     0.9567      1.963      1.142         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:35<00:00, 11.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 1.500s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.48s/it]\n",
      "                   all         20        367     0.0363      0.504      0.269      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/61         0G      0.896      1.162      1.064         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:35<00:00, 11.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 1.500s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.55s/it]\n",
      "                   all         20        367      0.972      0.189      0.299      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/61         0G     0.8591      1.021      1.045          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:35<00:00, 11.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.82s/it]\n",
      "                   all         20        367      0.938      0.329      0.474      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/61         0G      0.949     0.9728      1.093         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:25<00:00, 10.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.75s/it]\n",
      "                   all         20        367      0.957      0.368      0.561       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/61         0G     0.9077     0.9261      1.049         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:32<00:00, 10.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.26s/it]\n",
      "                   all         20        367      0.842       0.48       0.59      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/61         0G     0.9528     0.9035      1.026         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:26<00:00, 10.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.66s/it]\n",
      "                   all         20        367      0.754      0.504      0.539       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/61         0G     0.9592     0.9349      1.054         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:24<00:00, 10.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.24s/it]\n",
      "                   all         20        367      0.857      0.572       0.62      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/61         0G      1.002     0.9779      1.065         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:22<00:00, 10.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.18s/it]\n",
      "                   all         20        367      0.869      0.583      0.628      0.468\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/61         0G     0.8835     0.8586      1.017         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:24<00:00, 10.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.94s/it]\n",
      "                   all         20        367       0.91      0.608      0.647      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/61         0G     0.8448     0.8228      1.002         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:29<00:00, 10.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.17s/it]\n",
      "                   all         20        367      0.818      0.586      0.611      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/61         0G     0.8241     0.8196      1.015         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:25<00:00, 10.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.50s/it]\n",
      "                   all         20        367      0.872       0.61       0.65      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/61         0G     0.8316     0.9056      1.005         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:26<00:00, 10.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.40s/it]\n",
      "                   all         20        367      0.897       0.61      0.648       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/61         0G     0.8184     0.7776      1.001         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:30<00:00, 10.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.87s/it]\n",
      "                   all         20        367       0.88      0.621      0.658      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/61         0G     0.7751     0.7677     0.9957         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:23<00:00, 10.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.70s/it]\n",
      "                   all         20        367       0.88       0.64      0.659      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/61         0G     0.7547     0.7694      0.961         55        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:27<00:00, 10.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.88s/it]\n",
      "                   all         20        367      0.938      0.621      0.657      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/61         0G     0.7342     0.7254     0.9793         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:33<00:00, 10.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.11s/it]\n",
      "                   all         20        367      0.909      0.605       0.65       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/61         0G     0.7432     0.7067     0.9887         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:42<00:00, 11.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.68s/it]\n",
      "                   all         20        367       0.84      0.627      0.642      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/61         0G     0.7203     0.6888     0.9709         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:33<00:00, 10.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.11s/it]\n",
      "                   all         20        367      0.877      0.627      0.662      0.556\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/61         0G     0.6643      0.671     0.9487         13        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:25<00:00, 10.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.89s/it]\n",
      "                   all         20        367      0.907      0.635      0.679      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/61         0G     0.6958     0.6647     0.9642         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:22<00:00, 10.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.72s/it]\n",
      "                   all         20        367      0.928      0.634      0.681       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/61         0G     0.6975     0.6894      0.959         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:37<00:00, 11.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.80s/it]\n",
      "                   all         20        367      0.914      0.646      0.681      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/61         0G     0.6322     0.6605     0.9546         14        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:33<00:00, 10.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.18s/it]\n",
      "                   all         20        367      0.942      0.625      0.649      0.563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/61         0G     0.6581     0.6471     0.9741         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:30<00:00, 10.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.04s/it]\n",
      "                   all         20        367      0.913      0.635      0.677      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/61         0G     0.6606     0.6883     0.9513         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:24<00:00, 10.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.01s/it]\n",
      "                   all         20        367      0.945      0.614      0.658      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/61         0G     0.6372     0.6457     0.9461          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:25<00:00, 10.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.99s/it]\n",
      "                   all         20        367      0.954      0.629      0.679      0.569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/61         0G     0.5751     0.5926     0.9209          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:28<00:00, 10.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.88s/it]\n",
      "                   all         20        367      0.937      0.638      0.692      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/61         0G     0.6135     0.6207     0.9365         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:25<00:00, 10.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.60s/it]\n",
      "                   all         20        367      0.922      0.646      0.694      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/61         0G      0.549     0.5656     0.9218          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:24<00:00, 10.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.03s/it]\n",
      "                   all         20        367      0.936      0.646      0.689      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/61         0G     0.5647     0.5788     0.9277         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:23<00:00, 10.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.71s/it]\n",
      "                   all         20        367      0.957      0.646      0.682      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/61         0G     0.5488     0.5695     0.9266         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [02:24<00:00, 10.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.82s/it]\n",
      "                   all         20        367      0.957      0.651       0.68      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/61         0G      0.547     0.5572     0.9265        327        640:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 11/14 [02:05<00:33, 11.11s/it]"
     ]
    }
   ],
   "source": [
    "model.train(data=\"mydata.yaml\", epochs=61)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading a Previous Checkpoint\n",
    "now after some extensive training, we have a strong model stored in train 52. it will save after each training session. choose the best one by passing ```'\\best.pt'``` in the path argument."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model =YOLO('runs/detect/train55/weights/best.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the model on the validation dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata\\labels\\val.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.60s/it]\n",
      "                   all         20        367      0.957      0.649      0.699      0.641\n",
      "Speed: 5.8ms preprocess, 207.6ms inference, 0.0ms loss, 5.5ms postprocess per image\n"
     ]
    }
   ],
   "source": [
    "res = model.val(save=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "\n",
      "image 1/1 C:\\Users\\Nain0414\\DataspellProjects\\YOLOv8-Object-Detection-Transfer-Learning\\144.jpg: 640x640 8 rects, 869.7ms\n",
      "Speed: 3.0ms preprocess, 869.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001B[1mruns\\detect\\predict8\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res=model(\n",
    "    source='144.jpg',\n",
    "    conf=0.05,\n",
    "    save=True,\n",
    "    augment=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
      "type: <class 'torch.Tensor'>\n",
      "shape: torch.Size([11, 6])\n",
      "dtype: torch.float32\n",
      " + tensor([[3.55000e+02, 2.30000e+01, 3.77000e+02, 5.30000e+01, 9.89012e-01, 0.00000e+00],\n",
      "        [9.11000e+02, 9.90000e+01, 9.32000e+02, 1.30000e+02, 9.82678e-01, 0.00000e+00],\n",
      "        [6.33000e+02, 9.71000e+02, 6.54000e+02, 1.00100e+03, 9.77612e-01, 0.00000e+00],\n",
      "        [3.44000e+02, 3.19000e+02, 4.31000e+02, 7.10000e+02, 9.72000e-01, 0.00000e+00],\n",
      "        [7.72000e+02, 1.64000e+02, 7.93000e+02, 1.94000e+02, 9.71298e-01, 0.00000e+00],\n",
      "        [1.61000e+02, 3.19000e+02, 2.47000e+02, 7.11000e+02, 9.70618e-01, 0.00000e+00],\n",
      "        [4.37000e+02, 3.19000e+02, 5.22000e+02, 7.12000e+02, 9.65522e-01, 0.00000e+00],\n",
      "        [2.15000e+02, 7.27000e+02, 2.37000e+02, 7.57000e+02, 9.63343e-01, 0.00000e+00],\n",
      "        [0.00000e+00, 0.00000e+00, 5.00000e+00, 7.90000e+02, 8.83038e-02, 0.00000e+00],\n",
      "        [0.00000e+00, 3.03000e+02, 5.00000e+00, 1.02400e+03, 6.45926e-02, 0.00000e+00],\n",
      "        [0.00000e+00, 2.70000e+01, 5.00000e+00, 1.02400e+03, 6.29624e-02, 0.00000e+00]])]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from cv2 import imshow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import cv2\n",
    "#res = model(img)\n",
    "res_plotted = res[0].plot()\n",
    "cv2.imshow(\"result\", res_plotted)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 581, in _build_master\n",
      "    ws.require(__requires__)\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 909, in require\n",
      "    needed = self.resolve(parse_requirements(requirements))\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 800, in resolve\n",
      "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
      "pkg_resources.ContextualVersionConflict: (numpy 1.23.5 (c:\\users\\nain0414\\appdata\\local\\programs\\python\\python310\\lib\\site-packages), Requirement.parse('numpy<1.23.0,>=1.16.5'), {'scipy'})\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\yolo-script.py\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('ultralytics', 'console_scripts', 'yolo')())\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\yolo-script.py\", line 25, in importlib_load_entry_point\n",
      "    return next(matches).load()\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\metadata\\__init__.py\", line 171, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.yolo.engine.model import YOLO\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\__init__.py\", line 3, in <module>\n",
      "    from . import v8\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\__init__.py\", line 3, in <module>\n",
      "    from ultralytics.yolo.v8 import classify, detect, segment\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\classify\\__init__.py\", line 3, in <module>\n",
      "    from ultralytics.yolo.v8.classify.predict import ClassificationPredictor, predict\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\v8\\classify\\predict.py\", line 5, in <module>\n",
      "    from ultralytics.yolo.engine.predictor import BasePredictor\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\predictor.py\", line 37, in <module>\n",
      "    from ultralytics.nn.autobackend import AutoBackend\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\nn\\autobackend.py\", line 17, in <module>\n",
      "    from ultralytics.yolo.utils import LOGGER, ROOT, yaml_load\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\__init__.py\", line 622, in <module>\n",
      "    SETTINGS = get_settings()\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\__init__.py\", line 568, in get_settings\n",
      "    from ultralytics.yolo.utils.checks import check_version\n",
      "  File \"C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\utils\\checks.py\", line 17, in <module>\n",
      "    import pkg_resources as pkg\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 3260, in <module>\n",
      "    def _initialize_master_working_set():\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 3234, in _call_aside\n",
      "    f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 3272, in _initialize_master_working_set\n",
      "    working_set = WorkingSet._build_master()\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 583, in _build_master\n",
      "    return cls._build_from_requirements(__requires__)\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 596, in _build_from_requirements\n",
      "    dists = ws.resolve(reqs, Environment())\n",
      "  File \"C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pkg_resources\\__init__.py\", line 800, in resolve\n",
      "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
      "pkg_resources.ContextualVersionConflict: (numpy 1.23.5 (c:\\users\\nain0414\\appdata\\local\\programs\\python\\python310\\lib\\site-packages), Requirement.parse('numpy<1.23.0,>=1.16.5'), {'scipy'})\n"
     ]
    }
   ],
   "source": [
    "!yolo predict model=yolov8n.pt source='144.jpg' save=True augment=True\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters\n",
    "because our model performs well, it might"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img align=\"left\" src=\"https://blog.roboflow.com/content/images/size/w1000/2023/01/image-16.png\" width=\"1200\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from runs\\detect\\train55\\weights\\best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.9 MB)\n",
      "WARNING  YOLOv8 TensorFlow export is still under development. Please consider contributing to the effort if you have TF expertise. Thank you!\n",
      "\u001B[34m\u001B[1mTensorFlow SavedModel:\u001B[0m export failure  0.0s: cannot import name 'experimental_functions_run_eagerly' from 'tensorflow.python.eager.def_function' (C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43medgetpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\model.py:257\u001B[0m, in \u001B[0;36mYOLO.export\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    255\u001B[0m     args\u001B[38;5;241m.\u001B[39mbatch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m  \u001B[38;5;66;03m# default to 1 if not modified\u001B[39;00m\n\u001B[0;32m    256\u001B[0m exporter \u001B[38;5;241m=\u001B[39m Exporter(overrides\u001B[38;5;241m=\u001B[39margs)\n\u001B[1;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mexporter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\yolo\\engine\\exporter.py:247\u001B[0m, in \u001B[0;36mExporter.__call__\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m    244\u001B[0m     f[\u001B[38;5;241m7\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_tflite(s_model, nms\u001B[38;5;241m=\u001B[39mnms, agnostic_nms\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39magnostic_nms)\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m edgetpu:\n\u001B[0;32m    246\u001B[0m     f[\u001B[38;5;241m8\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_edgetpu(tflite_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(\n\u001B[1;32m--> 247\u001B[0m         \u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile\u001B[38;5;241m.\u001B[39mstem \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_full_integer_quant.tflite\u001B[39m\u001B[38;5;124m'\u001B[39m)))  \u001B[38;5;66;03m# int8 in/out\u001B[39;00m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tfjs:\n\u001B[0;32m    249\u001B[0m     f[\u001B[38;5;241m9\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_export_tfjs()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:960\u001B[0m, in \u001B[0;36mPath.__new__\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    958\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m Path:\n\u001B[0;32m    959\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m WindowsPath \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnt\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m PosixPath\n\u001B[1;32m--> 960\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_parts\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flavour\u001B[38;5;241m.\u001B[39mis_supported:\n\u001B[0;32m    962\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot instantiate \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m on your system\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    963\u001B[0m                               \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:594\u001B[0m, in \u001B[0;36mPurePath._from_parts\u001B[1;34m(cls, args)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    590\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_from_parts\u001B[39m(\u001B[38;5;28mcls\u001B[39m, args):\n\u001B[0;32m    591\u001B[0m     \u001B[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001B[39;00m\n\u001B[0;32m    592\u001B[0m     \u001B[38;5;66;03m# right flavour.\u001B[39;00m\n\u001B[0;32m    593\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m--> 594\u001B[0m     drv, root, parts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_drv \u001B[38;5;241m=\u001B[39m drv\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_root \u001B[38;5;241m=\u001B[39m root\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pathlib.py:578\u001B[0m, in \u001B[0;36mPurePath._parse_args\u001B[1;34m(cls, args)\u001B[0m\n\u001B[0;32m    576\u001B[0m     parts \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39m_parts\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 578\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    579\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(a, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    580\u001B[0m         \u001B[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001B[39;00m\n\u001B[0;32m    581\u001B[0m         parts\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mstr\u001B[39m(a))\n",
      "\u001B[1;31mTypeError\u001B[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "\n",
    "model.export(format='edgetpu')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:63: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n",
      "Ultralytics YOLOv8.0.42  Python-3.10.7 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from runs\\detect\\train55\\weights\\best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.9 MB)\n",
      "WARNING  YOLOv8 TensorFlow export is still under development. Please consider contributing to the effort if you have TF expertise. Thank you!\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.autotrackable has been moved to tensorflow.python.trackable.autotrackable. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "\u001B[34m\u001B[1mTensorFlow SavedModel:\u001B[0m export failure  5.4s: cannot import name 'experimental_functions_run_eagerly' from 'tensorflow.python.eager.def_function' (C:\\Users\\Nain0414\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py)\n",
      "\u001B[34m\u001B[1mTensorFlow Lite:\u001B[0m export success  0.0s, saved as runs\\detect\\train55\\weights\\best_saved_model\\best_float32.tflite (0.0 MB)\n",
      "\n",
      "Export complete (6.0s)\n",
      "Results saved to \u001B[1mC:\\Users\\Nain0414\\DataspellProjects\\YOLOv8-Object-Detection-Transfer-Learning\\runs\\detect\\train55\\weights\u001B[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\train55\\weights\\best_saved_model\\best_float32.tflite imgsz=640 \n",
      "Validate:        yolo val task=detect model=runs\\detect\\train55\\weights\\best_saved_model\\best_float32.tflite imgsz=640 data=C:\\Users\\Nain0414\\Downloads\\YOLO-v8-Transfer-Learning-Implementation-main\\YOLO-v8-Transfer-Learning-Implementation-main\\ultralytics\\ultralytics\\datasets\\mydata.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!yolo export model='runs/detect/train55/weights/best.pt' format=tflite"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
